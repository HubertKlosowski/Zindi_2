{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## GeoAI Ground-level NO2 Estimation Challenge by ITU\n",
    "\n",
    "### Author: Hubert Kłosowski 242424"
   ],
   "id": "f0aabc38d6194d97"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load data",
   "id": "23cf930fc71c9e50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train = pd.read_csv(os.path.join('data', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join('data', 'test.csv'))"
   ],
   "id": "1f81eac637fdb080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.info()",
   "id": "e701b0e967770c71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test.info()",
   "id": "4292f017cfe37df1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract date info",
   "id": "6a7791a54591251e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_date_info(dataframe):\n",
    "    dataframe['Date'] = pd.to_datetime(dataframe['Date'], format='mixed')\n",
    "    dataframe['DayOfWeek'] = dataframe['Date'].dt.dayofweek.astype('category')\n",
    "    dataframe['Month'] = dataframe['Date'].dt.month.astype('category')\n",
    "    dataframe['Year'] = dataframe['Date'].dt.year.astype('category')\n",
    "    dataframe['Week'] = dataframe['Date'].dt.isocalendar().week.astype('category')\n",
    "    dataframe['Season'] = get_season(dataframe['Date']).astype('category')\n",
    "    dataframe.drop(['Date'], axis=1, inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "def get_season(date_series):\n",
    "    spring = ((date_series.dt.month == 3) & (date_series.dt.day >= 20)) | ((date_series.dt.month > 3) & (date_series.dt.month < 6)) | ((date_series.dt.month == 6) & (date_series.dt.day <= 20))\n",
    "    summer = ((date_series.dt.month == 6) & (date_series.dt.day >= 21)) | ((date_series.dt.month > 6) & (date_series.dt.month < 9)) | ((date_series.dt.month == 9) & (date_series.dt.day <= 22))\n",
    "    autumn = ((date_series.dt.month == 9) & (date_series.dt.day >= 23)) | ((date_series.dt.month > 9) & (date_series.dt.month < 12)) | ((date_series.dt.month == 12) & (date_series.dt.day <= 20))\n",
    "    \n",
    "    season_series = pd.Series(0, index=date_series.index)  # Domyślnie 0 dla wiosny\n",
    "    season_series.loc[summer] = 1  # Lato\n",
    "    season_series.loc[autumn] = 2  # Jesień\n",
    "    season_series.loc[~(spring | summer | autumn)] = 3  # Zima\n",
    "    \n",
    "    return season_series\n",
    "\n",
    "train = extract_date_info(train)\n",
    "test = extract_date_info(test)"
   ],
   "id": "c24dddc52a93b86b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Target values in day of week",
   "id": "532f70eab5674371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.barplot(data=train, x='DayOfWeek', y='GT_NO2')",
   "id": "106f352bf09d3699",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Target values in months",
   "id": "a75dfe1206eb50d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.barplot(data=train, x='Month', y='GT_NO2')",
   "id": "f379bd2454f6cd1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Target values in years",
   "id": "f749f358ee995132"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "sns.barplot(data=train, x='Year', y='GT_NO2')",
   "id": "ff06cd2eea276a80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Target values in weeks",
   "id": "3a861a42bc18e54b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.barplot(data=train, x='Week', y='GT_NO2')"
   ],
   "id": "9a9c121158db58f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Target values in seasons",
   "id": "e627a78205c65a60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.barplot(data=train, x='Season', y='GT_NO2')"
   ],
   "id": "6680c53780a5267f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Map of id's in train dataset",
   "id": "d5d3e93aa0cc9637"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import folium\n",
    "\n",
    "\n",
    "my_map = folium.Map(\n",
    "    location=(train['LAT'].mean(), train['LON'].mean()),\n",
    "    zoom_start=7,\n",
    ")"
   ],
   "id": "59fe2b69ec2d8caa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Locations",
   "id": "dc83e8d29cdf84d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unique_train_locations = train.groupby(['LAT', 'LON'])['GT_NO2'].mean().reset_index()\n",
    "nans = train.loc[train['GT_NO2'].isna() == True, ['LAT', 'LON']].value_counts().to_frame().reset_index()\n",
    "unique_train_locations = pd.merge(unique_train_locations, nans, on=['LAT', 'LON'], how='outer')\n",
    "unique_train_locations.rename({'count': 'Nans'}, axis=1, inplace=True)\n",
    "unique_train_locations['Nans'] = unique_train_locations['Nans'].apply(lambda x: round(x / 10.96, 2))"
   ],
   "id": "66ce48de9a179ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "unique_train_locations",
   "id": "48793a936dcb43c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "layer_train_map = folium.FeatureGroup(name='Train Locations', show=False)\n",
    "for index, row in unique_train_locations.iterrows():\n",
    "    popup_html = f\"\"\"\n",
    "    <div style=\"font-family: Arial; font-size: 14px;\">\n",
    "        <strong>Mean GT_NO2 level:</strong> {row[\"GT_NO2\"]:.2f}<br>\n",
    "        <strong>Latitude:</strong> {row[\"LAT\"]}<br>\n",
    "        <strong>Longitude:</strong> {row[\"LON\"]}<br>\n",
    "        <strong>Percent of nans:</strong> {row['Nans']} %\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    popup = folium.Popup(popup_html, max_width=300)\n",
    "    if row['Nans'] > 10:\n",
    "        folium.Marker(\n",
    "            location=[row['LAT'], row['LON']],\n",
    "            icon=folium.Icon(color='green', icon_color='black', icon='home'),\n",
    "            popup=popup,\n",
    "        ).add_to(layer_train_map)\n",
    "    else:\n",
    "        folium.Marker(\n",
    "            location=[row['LAT'], row['LON']],\n",
    "            icon=folium.Icon(color='green', icon='home'),\n",
    "            popup=popup,\n",
    "        ).add_to(layer_train_map)\n",
    "    \n",
    "layer_train_map.add_to(my_map)"
   ],
   "id": "7762b1fe93999744",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test Locations",
   "id": "e5e17582e6ec4ee0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unique_test_locations = test[['LAT', 'LON']].drop_duplicates()\n",
    "\n",
    "layer_test_map = folium.FeatureGroup(name='Test Locations', show=False)\n",
    "for index, row in unique_test_locations.iterrows():\n",
    "    popup_html = f\"\"\"\n",
    "    <div style=\"font-family: Arial; font-size: 14px;\">\n",
    "        <strong>Latitude:</strong> {row[\"LAT\"]}<br>\n",
    "        <strong>Longitude:</strong> {row[\"LON\"]}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    popup = folium.Popup(popup_html, max_width=300)\n",
    "    folium.Marker(\n",
    "        location=[row['LAT'], row['LON']],\n",
    "        icon=folium.Icon(color='red', icon='home'),\n",
    "        popup=popup,\n",
    "    ).add_to(layer_test_map)\n",
    "    \n",
    "layer_test_map.add_to(my_map)"
   ],
   "id": "dda023fa14e0ab46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folium.LayerControl().add_to(my_map)\n",
    "my_map.save('my_map.html')"
   ],
   "id": "3ee799f292d36a50",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare data",
   "id": "8451323debc58a07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_ids = test['ID_Zindi']\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train.drop(columns=['ID', 'ID_Zindi'], axis=1, inplace=True)\n",
    "test.drop(columns=['ID', 'ID_Zindi'], axis=1, inplace=True)"
   ],
   "id": "3f145e854d730088",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fill NO2_trop with diff between NO2_total and NO2_strat",
   "id": "f4d97db7322df0c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train_random_num = np.random.uniform(-1e-6, 1e-6, size=len(train))\n",
    "# test_random_num = np.random.uniform(-1e-6, 1e-6, size=len(test))\n",
    "# train.fillna({'NO2_trop': train['NO2_total'] - train['NO2_strat'] + train_random_num}, inplace=True)\n",
    "# test.fillna({'NO2_trop': test['NO2_total'] - test['NO2_strat'] + test_random_num}, inplace=True)"
   ],
   "id": "91addc758361626",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get elevation from LAT, LON",
   "id": "24fd095721b13eec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "def get_elevation(lat, lon):\n",
    "    query = f'https://api.open-elevation.com/api/v1/lookup?locations={lat},{lon}'\n",
    "    r = requests.get(query).json()\n",
    "    return r['results'][0]['elevation']\n",
    "\n",
    "\n",
    "unique_train_locations['Elevation'] = unique_train_locations.apply(lambda r: get_elevation(r['LAT'], r['LON']), axis=1)\n",
    "unique_test_locations['Elevation'] = unique_test_locations.apply(lambda r: get_elevation(r['LAT'], r['LON']), axis=1)\n",
    "unique_train_locations.drop(columns=['Nans', 'GT_NO2'], inplace=True)\n",
    "\n",
    "train = train.merge(unique_train_locations, on=['LAT', 'LON'], how='left')\n",
    "test = test.merge(unique_test_locations, on=['LAT', 'LON'], how='left')"
   ],
   "id": "188e53a516999f42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check ranges of values",
   "id": "a1cce9ed29f38e95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train.describe()",
   "id": "a9dee96740331a76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Make the same ranges for test and train",
   "id": "d41f50aae08cb077"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cut_ranges():\n",
    "    for column in test.select_dtypes(exclude=['category']).columns[2:]:\n",
    "        test_min = test[column].min()\n",
    "        test_max = test[column].max()\n",
    "        to_drop = train[(train[column] < test_min) | (train[column] > test_max)].index\n",
    "        train.drop(index=to_drop, inplace=True)\n",
    "\n",
    "cut_ranges()\n",
    "\n",
    "train.describe()"
   ],
   "id": "f53a3710c41e9205",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Correlation Matrix for train",
   "id": "3bff7a7647dfa277"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(train.corr().round(2), annot=True, cmap='Greys')"
   ],
   "id": "665126196152aadd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Correlation Matrix for test",
   "id": "4624fc931f553310"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(test.corr().round(2), annot=True, cmap='Greys')"
   ],
   "id": "ede48e8943c9592a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scatter plots of columns from original dataset",
   "id": "e2c5b9c58cead8f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_scatter():\n",
    "    columns = [col for col in train.columns][:10]\n",
    "    fig, ax = plt.subplots(nrows=len(columns) // 5, ncols=5, figsize=(25, 15))\n",
    "    for i, col in enumerate(columns):\n",
    "        x_cord, y_cord = divmod(i, 5)\n",
    "        sns.scatterplot(data=train, x=col, y='GT_NO2', ax=ax[x_cord, y_cord], s=2)\n",
    "        ax[x_cord, y_cord].set_title(f'Correlation between {col} and GT_NO2')\n",
    "        ax[x_cord, y_cord].set_xlabel(col)\n",
    "        ax[x_cord, y_cord].set_ylabel('GT_NO2')\n",
    "\n",
    "\n",
    "plot_scatter()"
   ],
   "id": "16391601f6f34c42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Do sth with NaNs in GT_NO2\n",
    "\n",
    "train lightgbm to fill NaNs in train df\n",
    "filled rows use for final training, or drop"
   ],
   "id": "a9cc66a13f6ec310"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gt_no2_nans = train.loc[train['GT_NO2'].isna() == True, :]\n",
    "train.dropna(subset=['GT_NO2'], inplace=True)"
   ],
   "id": "7698129424720f4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Distribution of values",
   "id": "88de7e7d117ae6ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train['GT_NO2'].plot(kind='hist')",
   "id": "6dd7b9b6219118db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Identify outliers in target column using zscore",
   "id": "d9ac3b524cca81a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "detect_outliers = zscore(train['GT_NO2'])\n",
    "\n",
    "upper_quantiles = pd.DataFrame(list(zip(np.linspace(0.98, 1, 21), [np.quantile(detect_outliers, el) for el in np.linspace(0.98, 1, 21)], [np.quantile(train['GT_NO2'], el) for el in np.linspace(0.98, 1, 21)])), columns=['quantile', 'zscore', 'GT_NO2'])\n",
    "\n",
    "upper_quantiles"
   ],
   "id": "dac3f99800af8969",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lower_quantiles = pd.DataFrame(list(zip(np.linspace(0.0, 0.1, 21), [np.quantile(detect_outliers, el) for el in np.linspace(0.0, 0.1, 21)], [np.quantile(train['GT_NO2'], el) for el in np.linspace(0.0, 0.1, 21)])), columns=['quantile', 'zscore', 'GT_NO2'])\n",
    "\n",
    "lower_quantiles"
   ],
   "id": "d9f3b77cd055daf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Deleting outliers in top 1.4% percentile",
   "id": "eddd3393010c2b6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def del_gt_no2_outliers():\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    indexes_to_drop = []\n",
    "    q1, q2 = np.quantile(detect_outliers, 0.05), np.quantile(detect_outliers, 0.986)\n",
    "    for i, el in enumerate(detect_outliers):\n",
    "        if el > q2:\n",
    "            indexes_to_drop.append(i)\n",
    "    train.drop(indexes_to_drop, inplace=True)\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "del_gt_no2_outliers()\n",
    "\n",
    "train.info()"
   ],
   "id": "f420ca4ae59ebd1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training process",
   "id": "d3883c3dc90ac606"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "X, y = train.drop(columns=['GT_NO2'], axis=1), train['GT_NO2']\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X = pd.DataFrame(scaler.fit_transform(X), columns=scaler.feature_names_in_)\n",
    "# test = pd.DataFrame(scaler.transform(test), columns=scaler.feature_names_in_)"
   ],
   "id": "125ece808e32072d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)"
   ],
   "id": "8c4b1d27755fe75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GroupKFold"
   ],
   "id": "a6b6cc5620d54c43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LightGBM",
   "id": "a30cca249ac86ed1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def define_lightgbm_model(trial):\n",
    "    params = {\n",
    "        'max_bin': trial.suggest_int('max_bin', 70, 250),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 150, 400),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 2e-3, 1e-1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 400, 700),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0, log=True),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.8, log=True),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 100, 400),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 1, log=True),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 5),\n",
    "        'objective': 'root_mean_squared_error',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'tree_learner': 'voting',\n",
    "        'device': 'cpu',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 4,\n",
    "        'verbosity': -1,\n",
    "        # 'categorical_feature': 'name:Week,DayOfWeek,Year,Month,Season'\n",
    "        'categorical_feature': 'name:Season'\n",
    "    }\n",
    "    return lgb.LGBMRegressor(**params)\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    model = define_lightgbm_model(trial)\n",
    "    gkf = GroupKFold(n_splits=X['Season'].nunique())\n",
    "    scores = cross_val_score(model, X, y, groups=X['Season'], cv=gkf, n_jobs=-1, scoring='neg_root_mean_squared_error')\n",
    "    return scores.mean() * (-1)"
   ],
   "id": "bea89e57172f7da1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LightGBM study",
   "id": "137538be6f201369"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study_lightgbm = optuna.create_study(direction='minimize', study_name='GeoAIWithLightGBM', sampler=optuna.samplers.TPESampler())\n",
    "study_lightgbm.optimize(objective_lightgbm, n_trials=100)"
   ],
   "id": "883d48c32ca64783",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LightGBM tylko dla najbliższych danych",
   "id": "30531a5debbdfe2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# limit_train = pd.read_csv(os.path.join('data', 'train.csv'))\n",
    "# limit_test = pd.read_csv(os.path.join('data', 'test.csv'))\n",
    "# \n",
    "# limit_train = extract_date_info(limit_train)\n",
    "# limit_test = extract_date_info(limit_test)\n",
    "# \n",
    "# limit_train.reset_index(drop=True, inplace=True)\n",
    "# limit_train.drop(columns=['ID', 'ID_Zindi'], axis=1, inplace=True)\n",
    "# limit_test.drop(columns=['ID', 'ID_Zindi'], axis=1, inplace=True)\n",
    "# \n",
    "# train.dropna(subset=['GT_NO2'], inplace=True)\n",
    "# \n",
    "# limit_X, limit_y = train.drop(columns=['GT_NO2'], axis=1), train['GT_NO2']\n",
    "# \n",
    "# def objective_lightgbm_for_limit_data(trial):\n",
    "#     model = define_lightgbm_model(trial)\n",
    "#     gkf = GroupKFold(n_splits=X['DayOfWeek'].nunique())\n",
    "#     scores = cross_val_score(model, limit_X, limit_y, groups=X['DayOfWeek'], cv=gkf, n_jobs=-1, scoring='neg_root_mean_squared_error')\n",
    "#     return scores.mean() * (-1)\n",
    "# \n",
    "# study_lightgbm = optuna.create_study(direction='minimize', study_name='GeoAIWithLightGBM', sampler=optuna.samplers.TPESampler())\n",
    "# study_lightgbm.optimize(objective_lightgbm_for_limit_data, n_trials=200)"
   ],
   "id": "d115f80d8fdeee41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Narazie najlepszy model ever",
   "id": "f36550de5e8a160b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# best_params =  {'max_bin': 157, 'num_leaves': 284, 'max_depth': 12, 'learning_rate': 0.018943556979846253, 'n_estimators': 658, 'bagging_fraction': 0.9910723110875617, 'colsample_bytree': 0.4051901668168799, 'min_data_in_leaf': 54, 'reg_lambda': 0.047054010015969996, 'bagging_freq': 3, 'device': 'cpu', 'n_jobs': -1, 'random_state': 4, 'verbosity': -1, 'tree_learner': 'voting', 'objective': 'root_mean_squared_error', 'boosting_type': 'gbdt'}\n",
    "# \n",
    "# lgb_model = lgb.LGBMRegressor(**best_params)\n",
    "# lgb_model.fit(X, y)"
   ],
   "id": "a6a32ce8bd281fa8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lgb_model = define_lightgbm_model(study_lightgbm.best_trial)\n",
    "lgb_model.fit(X, y)"
   ],
   "id": "f3ad22a746458b9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use trained model to predict GTNO2 column, \n",
    "but in train dataset. Maybe it will learn better train dataset, and in records containing Nans GTNO2 there's sth"
   ],
   "id": "a6d2d542fe3d69b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# nans_X = gt_no2_nans.drop(columns=['GT_NO2'], axis=1)\n",
    "# nans_y = pd.DataFrame.from_dict({'GT_NO2': lgb_model.predict(nans_X)})\n",
    "# \n",
    "# X = pd.concat([nans_X, X], axis=0)\n",
    "# y = pd.concat([nans_y, y], axis=0)\n",
    "# \n",
    "# lgb_model.fit(X, y)"
   ],
   "id": "b2fa4ad3d898b450",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Validate model\n",
    "(just to be here)"
   ],
   "id": "5bb9d15f4834ec1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lightgbm_params = ['max_bin', 'num_leaves', 'max_depth', 'learning_rate', 'n_estimators', 'bagging_fraction', 'colsample_bytree', 'min_data_in_leaf']\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "root_mean_squared_error(y_test, lgb_pred)"
   ],
   "id": "f7886c5d8c7629f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import LearningCurveDisplay\n",
    "\n",
    "\n",
    "LearningCurveDisplay.from_estimator(lgb_model, X, y, cv=GroupKFold(n_splits=X['DayOfWeek'].nunique()), groups=X['DayOfWeek'], n_jobs=-1, random_state=4, scoring='neg_root_mean_squared_error')"
   ],
   "id": "213c43252d3eaa43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from sklearn.model_selection import LearningCurveDisplay\n",
    "# \n",
    "# \n",
    "# LearningCurveDisplay.from_estimator(lgb_model, limit_X, limit_y, cv=GroupKFold(n_splits=X['DayOfWeek'].nunique()), groups=X['DayOfWeek'], n_jobs=-1, random_state=4, scoring='neg_root_mean_squared_error')"
   ],
   "id": "5c4c21dd65a6681e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Best params",
   "id": "84042cc2e7b1b0de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "study_lightgbm.best_params",
   "id": "d62bb30f767aeac2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_to_csv(y_pred, save_as):\n",
    "    if 'result' not in os.listdir(os.getcwd()):\n",
    "        os.mkdir('result')\n",
    "    final_df = pd.concat([test_ids, pd.DataFrame.from_dict({'GT_NO2': y_pred})], axis=1)\n",
    "    final_df.to_csv(os.path.join('result', save_as), index=False)\n",
    "    \n",
    "save_to_csv(lgb_model.predict(test), 'lightgbm.csv')"
   ],
   "id": "c16ffef23cd7ed56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xd = pd.read_csv(os.path.join('result', 'lightgbm.csv'), header=0)\n",
    "xd['GT_NO2'] *= 0.95\n",
    "xd.to_csv(os.path.join('result', 'lightgbm_even_better.csv'), index=False)"
   ],
   "id": "f42d8225a5b2d402",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8b8899f06c77d541",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
